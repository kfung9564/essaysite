{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import language_check\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kappa metric for measuring agreement of automatic to human scores\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "\n",
    "def kappa(y_true, y_pred, weights=None, allow_off_by_one=False):\n",
    "    \"\"\"\n",
    "    From https://github.com/EducationalTestingService/skll/blob/master/skll/metrics.py\n",
    "    \n",
    "    Calculates the kappa inter-rater agreement between two the gold standard\n",
    "    and the predicted ratings. Potential values range from -1 (representing\n",
    "    complete disagreement) to 1 (representing complete agreement).  A kappa\n",
    "    value of 0 is expected if all agreement is due to chance.\n",
    "    In the course of calculating kappa, all items in ``y_true`` and ``y_pred`` will\n",
    "    first be converted to floats and then rounded to integers.\n",
    "    It is assumed that y_true and y_pred contain the complete range of possible\n",
    "    ratings.\n",
    "    This function contains a combination of code from yorchopolis's kappa-stats\n",
    "    and Ben Hamner's Metrics projects on Github.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of float\n",
    "        The true/actual/gold labels for the data.\n",
    "    y_pred : array-like of float\n",
    "        The predicted/observed labels for the data.\n",
    "    weights : str or np.array, optional\n",
    "        Specifies the weight matrix for the calculation.\n",
    "        Options are ::\n",
    "            -  None = unweighted-kappa\n",
    "            -  'quadratic' = quadratic-weighted kappa\n",
    "            -  'linear' = linear-weighted kappa\n",
    "            -  two-dimensional numpy array = a custom matrix of\n",
    "        weights. Each weight corresponds to the\n",
    "        :math:`w_{ij}` values in the wikipedia description\n",
    "        of how to calculate weighted Cohen's kappa.\n",
    "        Defaults to None.\n",
    "    allow_off_by_one : bool, optional\n",
    "        If true, ratings that are off by one are counted as\n",
    "        equal, and all other differences are reduced by\n",
    "        one. For example, 1 and 2 will be considered to be\n",
    "        equal, whereas 1 and 3 will have a difference of 1\n",
    "        for when building the weights matrix.\n",
    "        Defaults to False.\n",
    "    Returns\n",
    "    -------\n",
    "    k : float\n",
    "        The kappa score, or weighted kappa score.\n",
    "    Raises\n",
    "    ------\n",
    "    AssertionError\n",
    "        If ``y_true`` != ``y_pred``.\n",
    "    ValueError\n",
    "        If labels cannot be converted to int.\n",
    "    ValueError\n",
    "        If invalid weight scheme.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that the lists are both the same length\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "\n",
    "    # This rather crazy looking typecast is intended to work as follows:\n",
    "    # If an input is an int, the operations will have no effect.\n",
    "    # If it is a float, it will be rounded and then converted to an int\n",
    "    # because the ml_metrics package requires ints.\n",
    "    # If it is a str like \"1\", then it will be converted to a (rounded) int.\n",
    "    # If it is a str that can't be typecast, then the user is\n",
    "    # given a hopefully useful error message.\n",
    "    try:\n",
    "        y_true = [int(np.round(float(y))) for y in y_true]\n",
    "        y_pred = [int(np.round(float(y))) for y in y_pred]\n",
    "    except ValueError:\n",
    "        raise ValueError(\"For kappa, the labels should be integers or strings \"\n",
    "                         \"that can be converted to ints (E.g., '4.0' or '3').\")\n",
    "\n",
    "    # Figure out normalized expected values\n",
    "    min_rating = min(min(y_true), min(y_pred))\n",
    "    max_rating = max(max(y_true), max(y_pred))\n",
    "\n",
    "    # shift the values so that the lowest value is 0\n",
    "    # (to support scales that include negative values)\n",
    "    y_true = [y - min_rating for y in y_true]\n",
    "    y_pred = [y - min_rating for y in y_pred]\n",
    "\n",
    "    # Build the observed/confusion matrix\n",
    "    num_ratings = max_rating - min_rating + 1\n",
    "    observed = confusion_matrix(y_true, y_pred,\n",
    "                                labels=list(range(num_ratings)))\n",
    "    num_scored_items = float(len(y_true))\n",
    "\n",
    "    # Build weight array if weren't passed one\n",
    "    if isinstance(weights, str):\n",
    "        wt_scheme = weights\n",
    "        weights = None\n",
    "    else:\n",
    "        wt_scheme = ''\n",
    "    if weights is None:\n",
    "        weights = np.empty((num_ratings, num_ratings))\n",
    "        for i in range(num_ratings):\n",
    "            for j in range(num_ratings):\n",
    "                diff = abs(i - j)\n",
    "                if allow_off_by_one and diff:\n",
    "                    diff -= 1\n",
    "                if wt_scheme == 'linear':\n",
    "                    weights[i, j] = diff\n",
    "                elif wt_scheme == 'quadratic':\n",
    "                    weights[i, j] = diff ** 2\n",
    "                elif not wt_scheme:  # unweighted\n",
    "                    weights[i, j] = bool(diff)\n",
    "                else:\n",
    "                    raise ValueError('Invalid weight scheme specified for '\n",
    "                                     'kappa: {}'.format(wt_scheme))\n",
    "\n",
    "    hist_true = np.bincount(y_true, minlength=num_ratings)\n",
    "    hist_true = hist_true[: num_ratings] / num_scored_items\n",
    "    hist_pred = np.bincount(y_pred, minlength=num_ratings)\n",
    "    hist_pred = hist_pred[: num_ratings] / num_scored_items\n",
    "    expected = np.outer(hist_true, hist_pred)\n",
    "\n",
    "    # Normalize observed array\n",
    "    observed = observed / num_scored_items\n",
    "\n",
    "    # If all weights are zero, that means no disagreements matter.\n",
    "    k = 1.0\n",
    "    if np.count_nonzero(weights):\n",
    "        k -= (sum(sum(weights * observed)) / sum(sum(weights * expected)))\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_sets = pd.read_pickle('training_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [  \n",
    "                'word_count',\n",
    "                'corrections',\n",
    "                'similarity',\n",
    "                'token_count',\n",
    "                'unique_token_count',\n",
    "                'nostop_count',\n",
    "                'sent_count',\n",
    "                'ner_count',\n",
    "                'comma',\n",
    "                'question',\n",
    "                'exclamation',\n",
    "                'quotation',\n",
    "                'organization',\n",
    "                'caps',\n",
    "                'person',\n",
    "                'location',\n",
    "                'money',\n",
    "                'time',\n",
    "                'date',\n",
    "                'percent',\n",
    "                'noun',\n",
    "                'adj',\n",
    "                'pron',\n",
    "                'verb',\n",
    "                'cconj',\n",
    "                'adv',\n",
    "                'det',\n",
    "                'propn',\n",
    "                'num',\n",
    "                'part',\n",
    "                'intj',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>corrections</th>\n",
       "      <th>similarity</th>\n",
       "      <th>token_count</th>\n",
       "      <th>unique_token_count</th>\n",
       "      <th>nostop_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>ner_count</th>\n",
       "      <th>comma</th>\n",
       "      <th>question</th>\n",
       "      <th>...</th>\n",
       "      <th>adj</th>\n",
       "      <th>pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>cconj</th>\n",
       "      <th>adv</th>\n",
       "      <th>det</th>\n",
       "      <th>propn</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>intj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338</td>\n",
       "      <td>11</td>\n",
       "      <td>0.953891</td>\n",
       "      <td>396</td>\n",
       "      <td>181</td>\n",
       "      <td>204</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>19</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>456</td>\n",
       "      <td>206</td>\n",
       "      <td>237</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279</td>\n",
       "      <td>9</td>\n",
       "      <td>0.951935</td>\n",
       "      <td>305</td>\n",
       "      <td>162</td>\n",
       "      <td>153</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524</td>\n",
       "      <td>35</td>\n",
       "      <td>0.966408</td>\n",
       "      <td>579</td>\n",
       "      <td>266</td>\n",
       "      <td>332</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465</td>\n",
       "      <td>17</td>\n",
       "      <td>0.955189</td>\n",
       "      <td>516</td>\n",
       "      <td>211</td>\n",
       "      <td>252</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>0.925195</td>\n",
       "      <td>954</td>\n",
       "      <td>347</td>\n",
       "      <td>449</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>125</td>\n",
       "      <td>134</td>\n",
       "      <td>55</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>546</td>\n",
       "      <td>41</td>\n",
       "      <td>0.957361</td>\n",
       "      <td>644</td>\n",
       "      <td>230</td>\n",
       "      <td>329</td>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>817</td>\n",
       "      <td>23</td>\n",
       "      <td>0.952395</td>\n",
       "      <td>954</td>\n",
       "      <td>381</td>\n",
       "      <td>513</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>68</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>64</td>\n",
       "      <td>112</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>562</td>\n",
       "      <td>13</td>\n",
       "      <td>0.969016</td>\n",
       "      <td>666</td>\n",
       "      <td>258</td>\n",
       "      <td>355</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>467</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924272</td>\n",
       "      <td>530</td>\n",
       "      <td>235</td>\n",
       "      <td>299</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count  corrections  similarity  token_count  unique_token_count  \\\n",
       "0             338           11    0.953891          396                 181   \n",
       "1             419           19    0.954198          456                 206   \n",
       "2             279            9    0.951935          305                 162   \n",
       "3             524           35    0.966408          579                 266   \n",
       "4             465           17    0.955189          516                 211   \n",
       "...           ...          ...         ...          ...                 ...   \n",
       "12971         845           15    0.925195          954                 347   \n",
       "12972         546           41    0.957361          644                 230   \n",
       "12973         817           23    0.952395          954                 381   \n",
       "12974         562           13    0.969016          666                 258   \n",
       "12975         467            3    0.924272          530                 235   \n",
       "\n",
       "       nostop_count  sent_count  ner_count  comma  question  ...  adj  pron  \\\n",
       "0               204          19          3     18         2  ...   18    36   \n",
       "1               237          23         12     14         1  ...   23    35   \n",
       "2               153          23          5      9         0  ...   19    20   \n",
       "3               332          35         15     14         1  ...   41    21   \n",
       "4               252          30          6     13         0  ...   27    30   \n",
       "...             ...         ...        ...    ...       ...  ...  ...   ...   \n",
       "12971           449          51         41     50         0  ...   41   125   \n",
       "12972           329          55         24     22        10  ...   37    67   \n",
       "12973           513          52         29     47         7  ...   38    68   \n",
       "12974           355          44         10     40         2  ...   44    77   \n",
       "12975           299          32          6     26         0  ...   40    48   \n",
       "\n",
       "       verb  cconj  adv  det  propn  num  part  intj  \n",
       "0        51     14   18   32      5    0    16     2  \n",
       "1        83     18   26   45      7    5    10     1  \n",
       "2        40     16   13   32      1    3    10     0  \n",
       "3        80     17   25   55     29    0    24     2  \n",
       "4        80     16   40   60      3    3    21     0  \n",
       "...     ...    ...  ...  ...    ...  ...   ...   ...  \n",
       "12971   134     55   76   79     32   16    24     5  \n",
       "12972    82     28   54   64     12    5    17     5  \n",
       "12973   122     39   64  112     36    5    21     5  \n",
       "12974    78     22   62   67     11    4    10     1  \n",
       "12975    80     11   30   60      4    2    21     1  \n",
       "\n",
       "[12976 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_sets[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = essay_sets[all_features]\n",
    "y = essay_sets['adjusted_score'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['std_scaler.bin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "dump(sc, 'std_scaler.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=load('std_scaler.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000     100.00\n",
       "8867      25.75\n",
       "9439     100.00\n",
       "10093     75.25\n",
       "7481      75.25\n",
       "          ...  \n",
       "9318       1.00\n",
       "10177    100.00\n",
       "9648      75.25\n",
       "5894      34.00\n",
       "4917      34.00\n",
       "Name: adjusted_score, Length: 9083, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21215784, -0.47114778,  0.16915286, ..., -0.65016721,\n",
       "        -0.50962189, -0.41331823],\n",
       "       [-0.85046801, -1.11636985, -0.68560563, ..., -0.65016721,\n",
       "        -0.87507064,  0.38273128],\n",
       "       [ 0.20188119, -0.68622181,  0.78143018, ...,  0.46459801,\n",
       "        -0.38780564, -0.41331823],\n",
       "       ...,\n",
       "       [-0.40192573, -0.36361077, -0.12389136, ..., -0.65016721,\n",
       "        -0.38780564, -0.41331823],\n",
       "       [-1.01723373, -0.5786848 , -0.82877173, ..., -0.65016721,\n",
       "        -0.75325439, -0.41331823],\n",
       "       [-0.22365892, -0.68622181,  0.62496141, ..., -0.0927846 ,\n",
       "        -0.50962189, -0.41331823]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.38921601638812353\n",
      " \n",
      "kappa =  0.5475281291586523\n",
      "Processing time: 0:02:02.955716\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "\n",
    "paramgrid = {'l1_ratio': [.01, .1, .5, .9], 'alpha': [0.01, .1, 1]}\n",
    "\n",
    "gs = GridSearchCV(ElasticNet(max_iter=100000, random_state=26),\n",
    "                  param_grid=paramgrid,\n",
    "                  cv=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "dump(gs, 'elasticnet.joblib') \n",
    "\n",
    "y_pred = gs.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', gs.best_score_)\n",
    "print(' ')\n",
    "\n",
    "print('kappa = ', kappa(y_pred, y_test, weights='quadratic'))\n",
    "\n",
    "t1 = datetime.now()\n",
    "print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   2.5s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   2.5s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   2.5s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   2.4s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   2.5s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   2.6s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   2.7s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   2.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.6s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.7s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.6s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.6s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   2.4s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.6s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.6s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.6s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.7s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   2.6s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   3.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   3.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   2.8s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.3s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.2s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   3.1s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   2.6s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   2.5s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   2.6s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   2.6s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   2.6s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   2.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   2.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   2.8s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   3.3s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   3.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   3.3s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   3.3s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   3.4s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   5.2s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   5.5s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   5.2s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   5.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   5.3s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   2.9s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   3.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   2.9s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   2.7s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   2.7s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   2.7s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   2.7s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   2.9s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   2.8s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   2.9s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   2.9s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   3.5s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   3.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   3.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   3.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   3.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   8.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   8.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   8.2s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   8.4s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   8.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=  20.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=  19.7s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=  19.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=  20.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Processing time: 0:11:24.824130\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "\n",
    "parameters = {\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": [1,10,10,100,1000],\n",
    "    \"gamma\": [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(svm.SVR(), parameters, cv=5, verbose=2)\n",
    "grid_cv.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(grid_cv.best_params_)\n",
    "\n",
    "t1 = datetime.now()\n",
    "print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "kappa =  0.703568914366227\n",
      "Processing time: 0:00:05.170002\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "t0 = datetime.now()\n",
    "\n",
    "clf = svm.SVR(C=10, gamma=0.1)\n",
    "clf.fit(X_train_std, y_train)\n",
    "dump(clf, 'svr.joblib') \n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "\n",
    "# print('Accuracy: ', clf.best_score_)\n",
    "print(' ')\n",
    "\n",
    "print('kappa = ', kappa(y_pred, y_test, weights='quadratic'))\n",
    "\n",
    "t1 = datetime.now()\n",
    "print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5438604025974494\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test_std,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>corrections</th>\n",
       "      <th>similarity</th>\n",
       "      <th>token_count</th>\n",
       "      <th>unique_token_count</th>\n",
       "      <th>nostop_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>ner_count</th>\n",
       "      <th>comma</th>\n",
       "      <th>question</th>\n",
       "      <th>...</th>\n",
       "      <th>adj</th>\n",
       "      <th>pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>cconj</th>\n",
       "      <th>adv</th>\n",
       "      <th>det</th>\n",
       "      <th>propn</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>intj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338</td>\n",
       "      <td>11</td>\n",
       "      <td>0.953891</td>\n",
       "      <td>396</td>\n",
       "      <td>181</td>\n",
       "      <td>204</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>19</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>456</td>\n",
       "      <td>206</td>\n",
       "      <td>237</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279</td>\n",
       "      <td>9</td>\n",
       "      <td>0.951935</td>\n",
       "      <td>305</td>\n",
       "      <td>162</td>\n",
       "      <td>153</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524</td>\n",
       "      <td>35</td>\n",
       "      <td>0.966408</td>\n",
       "      <td>579</td>\n",
       "      <td>266</td>\n",
       "      <td>332</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465</td>\n",
       "      <td>17</td>\n",
       "      <td>0.955189</td>\n",
       "      <td>516</td>\n",
       "      <td>211</td>\n",
       "      <td>252</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>0.925195</td>\n",
       "      <td>954</td>\n",
       "      <td>347</td>\n",
       "      <td>449</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>125</td>\n",
       "      <td>134</td>\n",
       "      <td>55</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>546</td>\n",
       "      <td>41</td>\n",
       "      <td>0.957361</td>\n",
       "      <td>644</td>\n",
       "      <td>230</td>\n",
       "      <td>329</td>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>817</td>\n",
       "      <td>23</td>\n",
       "      <td>0.952395</td>\n",
       "      <td>954</td>\n",
       "      <td>381</td>\n",
       "      <td>513</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>68</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>64</td>\n",
       "      <td>112</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>562</td>\n",
       "      <td>13</td>\n",
       "      <td>0.969016</td>\n",
       "      <td>666</td>\n",
       "      <td>258</td>\n",
       "      <td>355</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>467</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924272</td>\n",
       "      <td>530</td>\n",
       "      <td>235</td>\n",
       "      <td>299</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count  corrections  similarity  token_count  unique_token_count  \\\n",
       "0             338           11    0.953891          396                 181   \n",
       "1             419           19    0.954198          456                 206   \n",
       "2             279            9    0.951935          305                 162   \n",
       "3             524           35    0.966408          579                 266   \n",
       "4             465           17    0.955189          516                 211   \n",
       "...           ...          ...         ...          ...                 ...   \n",
       "12971         845           15    0.925195          954                 347   \n",
       "12972         546           41    0.957361          644                 230   \n",
       "12973         817           23    0.952395          954                 381   \n",
       "12974         562           13    0.969016          666                 258   \n",
       "12975         467            3    0.924272          530                 235   \n",
       "\n",
       "       nostop_count  sent_count  ner_count  comma  question  ...  adj  pron  \\\n",
       "0               204          19          3     18         2  ...   18    36   \n",
       "1               237          23         12     14         1  ...   23    35   \n",
       "2               153          23          5      9         0  ...   19    20   \n",
       "3               332          35         15     14         1  ...   41    21   \n",
       "4               252          30          6     13         0  ...   27    30   \n",
       "...             ...         ...        ...    ...       ...  ...  ...   ...   \n",
       "12971           449          51         41     50         0  ...   41   125   \n",
       "12972           329          55         24     22        10  ...   37    67   \n",
       "12973           513          52         29     47         7  ...   38    68   \n",
       "12974           355          44         10     40         2  ...   44    77   \n",
       "12975           299          32          6     26         0  ...   40    48   \n",
       "\n",
       "       verb  cconj  adv  det  propn  num  part  intj  \n",
       "0        51     14   18   32      5    0    16     2  \n",
       "1        83     18   26   45      7    5    10     1  \n",
       "2        40     16   13   32      1    3    10     0  \n",
       "3        80     17   25   55     29    0    24     2  \n",
       "4        80     16   40   60      3    3    21     0  \n",
       "...     ...    ...  ...  ...    ...  ...   ...   ...  \n",
       "12971   134     55   76   79     32   16    24     5  \n",
       "12972    82     28   54   64     12    5    17     5  \n",
       "12973   122     39   64  112     36    5    21     5  \n",
       "12974    78     22   62   67     11    4    10     1  \n",
       "12975    80     11   30   60      4    2    21     1  \n",
       "\n",
       "[12976 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In â€œLet there be dark,â€ Paul talks about the i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               essay\n",
       "0  In â€œLet there be dark,â€ Paul talks about the i..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_essay = \"In â€œLet there be dark,â€ Paul talks about the importance of darkness. Darkness is essential to humans. He states, â€œOur bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of â€œshort sleepâ€ is â€œlong light.â€ Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isnâ€™t a place for this much artificial light in our lives.â€ (2). Here, He talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy. Animals also need darkness. He states, â€œThe rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well knownâ€”the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggsâ€”and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the worldâ€™s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earthâ€™s ecology would collapse...â€ (2). Here he explains that animals, too, need darkness to survive.\"\n",
    "d = {'essay': [sample_essay]}\n",
    "essay_data = pd.DataFrame(data=d)\n",
    "\n",
    "essay_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_data['word_count'] = essay_data['essay'].str.strip().str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matches</th>\n",
       "      <th>corrections</th>\n",
       "      <th>corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Line 1, column 163, Rule ID: MORFOLOGIK_RULE_...</td>\n",
       "      <td>2</td>\n",
       "      <td>In â€œLet there be dark,â€ Paul talks about the i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             matches  corrections  \\\n",
       "0  [Line 1, column 163, Rule ID: MORFOLOGIK_RULE_...            2   \n",
       "\n",
       "                                           corrected  \n",
       "0  In â€œLet there be dark,â€ Paul talks about the i...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool = language_check.LanguageTool('en-US')\n",
    "\n",
    "essay_data['matches'] = essay_data['essay'].apply(lambda txt: tool.check(txt))\n",
    "essay_data['corrections'] = essay_data.apply(lambda l: len(l['matches']), axis=1)\n",
    "essay_data['corrected'] = essay_data.apply(lambda l: language_check.correct(l['essay'], l['matches']), axis=1)\n",
    "\n",
    "essay_data[['matches', 'corrections', 'corrected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In â€œLet there be dark,â€ Paul talks about the importance of darkness. Darkness is essential to humans. He states, â€œOur bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of â€œshort sleepâ€ is â€œlong light.â€ Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isnâ€™t a place for this much artificial light in our lives.â€ (2). Here, He talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy. Animals also need darkness. He states, â€œThe rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well knownâ€”the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggsâ€”and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the worldâ€™s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earthâ€™s ecology would collapse...â€ (2). Here he explains that animals, too, need darkness to survive.\n",
      "\n",
      "In â€œLet there be dark,â€ Paul talks about the importance of darkness. Darkness is essential to humans. He states, â€œOur bodies need darkness to produce the hormone melanin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of â€œshort sleepâ€ is â€œlong light.â€ Whether we work at night or simply take our tablets, notebooks and smart phones to bed, there isnâ€™t a place for this much artificial light in our lives.â€ (2). Here, He talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy. Animals also need darkness. He states, â€œThe rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well knownâ€”the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggsâ€”and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the worldâ€™s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earthâ€™s ecology would collapse...â€ (2). Here he explains that animals, too, need darkness to survive.\n"
     ]
    }
   ],
   "source": [
    "print(essay_data['essay'][0])\n",
    "print()\n",
    "print(essay_data['corrected'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "sents = []\n",
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "ner = []\n",
    "\n",
    "stop_words = set(STOP_WORDS)\n",
    "stop_words.update(punctuation) # remove it if you need punctuation \n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "t0 = datetime.now()\n",
    "\n",
    "# suppress numpy warnings\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "for essay in nlp.pipe(essay_data['corrected']):\n",
    "    tokens.append([e.text for e in essay])\n",
    "    sents.append([sent.string.strip() for sent in essay.sents])\n",
    "    pos.append([e.pos_ for e in essay])\n",
    "    ner.append([e.text for e in essay.ents])\n",
    "    lemma.append([n.lemma_ for n in essay])\n",
    "\n",
    "\n",
    "essay_data['tokens'] = tokens\n",
    "essay_data['lemma'] = lemma\n",
    "essay_data['pos'] = pos\n",
    "essay_data['sents'] = sents\n",
    "essay_data['ner'] = ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>sents</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[In, â€œ, Let, there, be, dark, ,, â€, Paul, talk...</td>\n",
       "      <td>[ADP, PUNCT, VERB, PRON, AUX, ADJ, PUNCT, PUNC...</td>\n",
       "      <td>[In â€œLet there be dark,â€ Paul talks about the ...</td>\n",
       "      <td>[night, 2, 400, North America, American, billi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [In, â€œ, Let, there, be, dark, ,, â€, Paul, talk...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [ADP, PUNCT, VERB, PRON, AUX, ADJ, PUNCT, PUNC...   \n",
       "\n",
       "                                               sents  \\\n",
       "0  [In â€œLet there be dark,â€ Paul talks about the ...   \n",
       "\n",
       "                                                 ner  \n",
       "0  [night, 2, 400, North America, American, billi...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_data[['tokens', 'pos', 'sents', 'ner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "reference_essays = {1: 161, 2: 3022, 3: 5263, 4: 5341, 5: 7209, 6: 8896, 7: 11796, 8: 12340} # topic: essay_id\n",
    "\n",
    "references = {}\n",
    "\n",
    "stop_words = set(STOP_WORDS)\n",
    "\n",
    "# generate nlp object for reference essays:\n",
    "for topic, index in reference_essays.items():\n",
    "    references[topic] = nlp(essay_sets.iloc[index]['essay'])\n",
    "\n",
    "\n",
    "def avg_similarity(essay):\n",
    "    sim = 0\n",
    "    \n",
    "    for ref in references:\n",
    "        sim += nlp(essay).similarity(references[ref])\n",
    "    \n",
    "    return sim / 8\n",
    "    \n",
    "    \n",
    "essay_data['similarity'] = essay_data.apply(lambda row: avg_similarity(row['essay']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.799273\n",
       "Name: similarity, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_data['similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_data['token_count'] = essay_data.apply(lambda x: len(x['tokens']), axis=1)\n",
    "essay_data['unique_token_count'] = essay_data.apply(lambda x: len(set(x['tokens'])), axis=1)\n",
    "essay_data['nostop_count'] = essay_data \\\n",
    "            .apply(lambda x: len([token for token in x['tokens'] if token not in stop_words]), axis=1)\n",
    "essay_data['sent_count'] = essay_data.apply(lambda x: len(x['sents']), axis=1)\n",
    "essay_data['ner_count'] = essay_data.apply(lambda x: len(x['ner']), axis=1)\n",
    "essay_data['comma'] = essay_data.apply(lambda x: x['corrected'].count(','), axis=1)\n",
    "essay_data['question'] = essay_data.apply(lambda x: x['corrected'].count('?'), axis=1)\n",
    "essay_data['exclamation'] = essay_data.apply(lambda x: x['corrected'].count('!'), axis=1)\n",
    "essay_data['quotation'] = essay_data.apply(lambda x: x['corrected'].count('\"') + x['corrected'].count(\"'\"), axis=1)\n",
    "essay_data['organization'] = essay_data.apply(lambda x: x['corrected'].count(r'@ORGANIZATION'), axis=1)\n",
    "essay_data['caps'] = essay_data.apply(lambda x: x['corrected'].count(r'@CAPS'), axis=1)\n",
    "essay_data['person'] = essay_data.apply(lambda x: x['corrected'].count(r'@PERSON'), axis=1)\n",
    "essay_data['location'] = essay_data.apply(lambda x: x['corrected'].count(r'@LOCATION'), axis=1)\n",
    "essay_data['money'] = essay_data.apply(lambda x: x['corrected'].count(r'@MONEY'), axis=1)\n",
    "essay_data['time'] = essay_data.apply(lambda x: x['corrected'].count(r'@TIME'), axis=1)\n",
    "essay_data['date'] = essay_data.apply(lambda x: x['corrected'].count(r'@DATE'), axis=1)\n",
    "essay_data['percent'] = essay_data.apply(lambda x: x['corrected'].count(r'@PERCENT'), axis=1)\n",
    "essay_data['noun'] = essay_data.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
    "essay_data['adj'] = essay_data.apply(lambda x: x['pos'].count('ADJ'), axis=1)\n",
    "essay_data['pron'] = essay_data.apply(lambda x: x['pos'].count('PRON'), axis=1)\n",
    "essay_data['verb'] = essay_data.apply(lambda x: x['pos'].count('VERB'), axis=1)\n",
    "essay_data['noun'] = essay_data.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
    "essay_data['cconj'] = essay_data.apply(lambda x: x['pos'].count('CCONJ'), axis=1)\n",
    "essay_data['adv'] = essay_data.apply(lambda x: x['pos'].count('ADV'), axis=1)\n",
    "essay_data['det'] = essay_data.apply(lambda x: x['pos'].count('DET'), axis=1)\n",
    "essay_data['propn'] = essay_data.apply(lambda x: x['pos'].count('PROPN'), axis=1)\n",
    "essay_data['num'] = essay_data.apply(lambda x: x['pos'].count('NUM'), axis=1)\n",
    "essay_data['part'] = essay_data.apply(lambda x: x['pos'].count('PART'), axis=1)\n",
    "essay_data['intj'] = essay_data.apply(lambda x: x['pos'].count('INTJ'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>matches</th>\n",
       "      <th>corrections</th>\n",
       "      <th>corrected</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>sents</th>\n",
       "      <th>ner</th>\n",
       "      <th>...</th>\n",
       "      <th>adj</th>\n",
       "      <th>pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>cconj</th>\n",
       "      <th>adv</th>\n",
       "      <th>det</th>\n",
       "      <th>propn</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>intj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In â€œLet there be dark,â€ Paul talks about the i...</td>\n",
       "      <td>234</td>\n",
       "      <td>[Line 1, column 163, Rule ID: MORFOLOGIK_RULE_...</td>\n",
       "      <td>2</td>\n",
       "      <td>In â€œLet there be dark,â€ Paul talks about the i...</td>\n",
       "      <td>[In, â€œ, Let, there, be, dark, ,, â€, Paul, talk...</td>\n",
       "      <td>[in, \", let, there, be, dark, ,, \", Paul, talk...</td>\n",
       "      <td>[ADP, PUNCT, VERB, PRON, AUX, ADJ, PUNCT, PUNC...</td>\n",
       "      <td>[In â€œLet there be dark,â€ Paul talks about the ...</td>\n",
       "      <td>[night, 2, 400, North America, American, billi...</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               essay  word_count  \\\n",
       "0  In â€œLet there be dark,â€ Paul talks about the i...         234   \n",
       "\n",
       "                                             matches  corrections  \\\n",
       "0  [Line 1, column 163, Rule ID: MORFOLOGIK_RULE_...            2   \n",
       "\n",
       "                                           corrected  \\\n",
       "0  In â€œLet there be dark,â€ Paul talks about the i...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [In, â€œ, Let, there, be, dark, ,, â€, Paul, talk...   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  [in, \", let, there, be, dark, ,, \", Paul, talk...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [ADP, PUNCT, VERB, PRON, AUX, ADJ, PUNCT, PUNC...   \n",
       "\n",
       "                                               sents  \\\n",
       "0  [In â€œLet there be dark,â€ Paul talks about the ...   \n",
       "\n",
       "                                                 ner  ...  adj  pron  verb  \\\n",
       "0  [night, 2, 400, North America, American, billi...  ...   20     7    31   \n",
       "\n",
       "   cconj  adv  det  propn  num  part  intj  \n",
       "0     10   10   27      4    5     9     0  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = clf.predict(essay_features)\n",
    "\n",
    "score_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(essay_text):\n",
    "    d = {'essay': [essay_text]}\n",
    "    essay_data = pd.DataFrame(data=d)\n",
    "    \n",
    "    essay_data['word_count'] = essay_data['essay'].str.strip().str.split().str.len()\n",
    "    \n",
    "    tool = language_check.LanguageTool('en-US')\n",
    "\n",
    "    essay_data['matches'] = essay_data['essay'].apply(lambda txt: tool.check(txt))\n",
    "    essay_data['corrections'] = essay_data.apply(lambda l: len(l['matches']), axis=1)\n",
    "    essay_data['corrected'] = essay_data.apply(lambda l: language_check.correct(l['essay'], l['matches']), axis=1)\n",
    "\n",
    "    sents = []\n",
    "    tokens = []\n",
    "    lemma = []\n",
    "    pos = []\n",
    "    ner = []\n",
    "\n",
    "    stop_words = set(STOP_WORDS)\n",
    "    stop_words.update(punctuation)\n",
    "\n",
    "    nlp = en_core_web_sm.load()\n",
    "\n",
    "    np.warnings.filterwarnings('ignore')\n",
    "\n",
    "    for essay in nlp.pipe(essay_data['corrected']):\n",
    "        tokens.append([e.text for e in essay])\n",
    "        sents.append([sent.string.strip() for sent in essay.sents])\n",
    "        pos.append([e.pos_ for e in essay])\n",
    "        ner.append([e.text for e in essay.ents])\n",
    "        lemma.append([n.lemma_ for n in essay])\n",
    "\n",
    "    essay_data['tokens'] = tokens\n",
    "    essay_data['lemma'] = lemma\n",
    "    essay_data['pos'] = pos\n",
    "    essay_data['sents'] = sents\n",
    "    essay_data['ner'] = ner\n",
    "    \n",
    "    essay_data['similarity'] = essay_data.apply(lambda row: avg_similarity(row['essay']), axis=1)\n",
    "    \n",
    "    essay_data['token_count'] = essay_data.apply(lambda x: len(x['tokens']), axis=1)\n",
    "    essay_data['unique_token_count'] = essay_data.apply(lambda x: len(set(x['tokens'])), axis=1)\n",
    "    essay_data['nostop_count'] = essay_data \\\n",
    "            .apply(lambda x: len([token for token in x['tokens'] if token not in stop_words]), axis=1)\n",
    "    essay_data['sent_count'] = essay_data.apply(lambda x: len(x['sents']), axis=1)\n",
    "    essay_data['ner_count'] = essay_data.apply(lambda x: len(x['ner']), axis=1)\n",
    "    essay_data['comma'] = essay_data.apply(lambda x: x['corrected'].count(','), axis=1)\n",
    "    essay_data['question'] = essay_data.apply(lambda x: x['corrected'].count('?'), axis=1)\n",
    "    essay_data['exclamation'] = essay_data.apply(lambda x: x['corrected'].count('!'), axis=1)\n",
    "    essay_data['quotation'] = essay_data.apply(lambda x: x['corrected'].count('\"') + x['corrected'].count(\"'\"), axis=1)\n",
    "    essay_data['organization'] = essay_data.apply(lambda x: x['corrected'].count(r'@ORGANIZATION'), axis=1)\n",
    "    essay_data['caps'] = essay_data.apply(lambda x: x['corrected'].count(r'@CAPS'), axis=1)\n",
    "    essay_data['person'] = essay_data.apply(lambda x: x['corrected'].count(r'@PERSON'), axis=1)\n",
    "    essay_data['location'] = essay_data.apply(lambda x: x['corrected'].count(r'@LOCATION'), axis=1)\n",
    "    essay_data['money'] = essay_data.apply(lambda x: x['corrected'].count(r'@MONEY'), axis=1)\n",
    "    essay_data['time'] = essay_data.apply(lambda x: x['corrected'].count(r'@TIME'), axis=1)\n",
    "    essay_data['date'] = essay_data.apply(lambda x: x['corrected'].count(r'@DATE'), axis=1)\n",
    "    essay_data['percent'] = essay_data.apply(lambda x: x['corrected'].count(r'@PERCENT'), axis=1)\n",
    "    essay_data['noun'] = essay_data.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
    "    essay_data['adj'] = essay_data.apply(lambda x: x['pos'].count('ADJ'), axis=1)\n",
    "    essay_data['pron'] = essay_data.apply(lambda x: x['pos'].count('PRON'), axis=1)\n",
    "    essay_data['verb'] = essay_data.apply(lambda x: x['pos'].count('VERB'), axis=1)\n",
    "    essay_data['noun'] = essay_data.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
    "    essay_data['cconj'] = essay_data.apply(lambda x: x['pos'].count('CCONJ'), axis=1)\n",
    "    essay_data['adv'] = essay_data.apply(lambda x: x['pos'].count('ADV'), axis=1)\n",
    "    essay_data['det'] = essay_data.apply(lambda x: x['pos'].count('DET'), axis=1)\n",
    "    essay_data['propn'] = essay_data.apply(lambda x: x['pos'].count('PROPN'), axis=1)\n",
    "    essay_data['num'] = essay_data.apply(lambda x: x['pos'].count('NUM'), axis=1)\n",
    "    essay_data['part'] = essay_data.apply(lambda x: x['pos'].count('PART'), axis=1)\n",
    "    essay_data['intj'] = essay_data.apply(lambda x: x['pos'].count('INTJ'), axis=1)\n",
    "    \n",
    "    return essay_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My little brother is so irritating. All day long he says, â€œEddie, I wonder why people can talk but animals canâ€™t.â€ Or, â€œI wonder why the ocean looks blue.â€ Of course, I donâ€™t know the answers, but I donâ€™t let him know that. I just make up reasonable explanations, and he accepts them as if Iâ€™m the smartest person in the world. Before I answer one of his questions, I usually tell him that heâ€™s pretty stupid and asks too many questions. Well, yesterday we both got our report cards. I got Bâ€™s and Câ€™s, and he got straight Aâ€™s. Under the â€œCommentsâ€ section on my report card, it said, â€œEddie would be getting better grades if he asked more questions.â€ Of course, on my brotherâ€™s report card, it said just the opposite. To make things worse, my brother squawked all day about how I was so stupid for not asking questions! I just sighed and told him he was rightâ€”I wouldn't make fun of him anymore for asking so many questions. Yes, I learned a lesson from my little brother: Never be afraid to ask questions, and NEVER be afraid to wonder why.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_essay2 = \"My little brother is so irritating. All day long he says, â€œEddie, I wonder why people can talk but animals canâ€™t.â€ Or, â€œI wonder why the ocean looks blue.â€ Of course, I donâ€™t know the answers, but I donâ€™t let him know that. I just make up reasonable explanations, and he accepts them as if Iâ€™m the smartest person in the world. Before I answer one of his questions, I usually tell him that heâ€™s pretty stupid and asks too many questions. Well, yesterday we both got our report cards. I got Bâ€™s and Câ€™s, and he got straight Aâ€™s. Under the â€œCommentsâ€ section on my report card, it said, â€œEddie would be getting better grades if he asked more questions.â€ Of course, on my brotherâ€™s report card, it said just the opposite. To make things worse, my brother squawked all day about how I was so stupid for not asking questions! I just sighed and told him he was rightâ€”I wouldn't make fun of him anymore for asking so many questions. Yes, I learned a lesson from my little brother: Never be afraid to ask questions, and NEVER be afraid to wonder why.\"\n",
    "\n",
    "sample_essay2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In â€œLet there be dark,â€ Paul talks about the importance of darkness. Darkness is essential to humans. He states, â€œOur bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of â€œshort sleepâ€ is â€œlong light.â€ Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isnâ€™t a place for this much artificial light in our lives.â€ (2). Here, He talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy. Animals also need darkness. He states, â€œThe rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well knownâ€”the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggsâ€”and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the worldâ€™s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earthâ€™s ecology would collapse...â€ (2). Here he explains that animals, too, need darkness to survive.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.46911379])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay1 = extract_features(sample_essay)\n",
    "essay1_scaled = sc.transform(essay1[all_features])\n",
    "e_pred1 = clf.predict(essay1_scaled)\n",
    "\n",
    "e_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>corrections</th>\n",
       "      <th>similarity</th>\n",
       "      <th>token_count</th>\n",
       "      <th>unique_token_count</th>\n",
       "      <th>nostop_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>ner_count</th>\n",
       "      <th>comma</th>\n",
       "      <th>question</th>\n",
       "      <th>...</th>\n",
       "      <th>adj</th>\n",
       "      <th>pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>cconj</th>\n",
       "      <th>adv</th>\n",
       "      <th>det</th>\n",
       "      <th>propn</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>intj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.799273</td>\n",
       "      <td>294</td>\n",
       "      <td>161</td>\n",
       "      <td>156</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  corrections  similarity  token_count  unique_token_count  \\\n",
       "0         234            2    0.799273          294                 161   \n",
       "\n",
       "   nostop_count  sent_count  ner_count  comma  question  ...  adj  pron  verb  \\\n",
       "0           156          16         11     22         0  ...   20     7    31   \n",
       "\n",
       "   cconj  adv  det  propn  num  part  intj  \n",
       "0     10   10   27      4    5     9     0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay1[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.83724891])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay2 = extract_features(sample_essay2)\n",
    "essay2_scaled = sc.transform(essay2[all_features])\n",
    "e_pred2 = clf.predict(essay2_scaled)\n",
    "\n",
    "e_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>corrections</th>\n",
       "      <th>similarity</th>\n",
       "      <th>token_count</th>\n",
       "      <th>unique_token_count</th>\n",
       "      <th>nostop_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>ner_count</th>\n",
       "      <th>comma</th>\n",
       "      <th>question</th>\n",
       "      <th>...</th>\n",
       "      <th>adj</th>\n",
       "      <th>pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>cconj</th>\n",
       "      <th>adv</th>\n",
       "      <th>det</th>\n",
       "      <th>propn</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>intj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854395</td>\n",
       "      <td>244</td>\n",
       "      <td>126</td>\n",
       "      <td>119</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  corrections  similarity  token_count  unique_token_count  \\\n",
       "0         194            0    0.854395          244                 126   \n",
       "\n",
       "   nostop_count  sent_count  ner_count  comma  question  ...  adj  pron  verb  \\\n",
       "0           119          14          5     16         0  ...   15    27    37   \n",
       "\n",
       "   cconj  adv  det  propn  num  part  intj  \n",
       "0      9   22   18      6    1     9     2  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay2[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'H:\\Tesseract\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-book readers are changing the way people read, or so e-book developers hope. The main\n",
      "selling point for these handheld devices, which are sort of the size of a paperback\n",
      "book, is that they make books easy to access and carry. Electronic versions of printed\n",
      "books can be downloaded online for a few bucks or directly from your cell phone. These\n",
      "devices can store hundreds of books in memory and, with text-to-speech features, can\n",
      "even read the texts. The market for e-books and e-book readers keeps expanding as a lot\n",
      "of companies enter it. Online and traditional booksellers have been the first to market\n",
      "e-book readers to the public, but computer companies, especially the ones already\n",
      "involved in cell phone, online music, and notepad computer technology, will also enter\n",
      "the market. The problem for consumers, however, is which device to choose.\n",
      "Incompatibility is the norm. E-books can be read only on the devices they were intended\n",
      "for. Furthermore, use is restricted by the same kind of DRM systems that restrict the\n",
      "copying of music and videos. So, book buyers are often unable to lend books to other\n",
      "readers, as they can with a real book. Few accommodations have been made to fit the\n",
      "other way Americans read: by borrowing books from libraries. What is a buyer to do?\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"images/essay.jpg\")\n",
    "\n",
    "thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "result = cv2.GaussianBlur(thresh, (5,5), 0)\n",
    "result = 255 - result\n",
    "\n",
    "data = pytesseract.image_to_string(result, lang='eng',config='--psm 6')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(essay_text):\n",
    "    essay = extract_features(essay_text)\n",
    "    essay_scaled = sc.transform(essay[all_features])\n",
    "    score_pred = clf.predict(essay_scaled)\n",
    "\n",
    "    return score_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.8516039844114"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "\n",
    "anvil.server.connect(\"7P3FVJT7THECP7ODOIFSU3CV-WQQNE63QV6PTSW4S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media\n",
    "\n",
    "@anvil.server.callable\n",
    "def text_from_image(file):\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        image = cv2.imread(filename)\n",
    "\n",
    "    thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    result = cv2.GaussianBlur(thresh, (5,5), 0)\n",
    "    result = 255 - result\n",
    "\n",
    "    data = pytesseract.image_to_string(result, lang='eng',config='--psm 6')\n",
    "    return data\n",
    "\n",
    "\n",
    "@anvil.server.callable\n",
    "def get_score(text):\n",
    "    num_score = predict_score(text)\n",
    "    letter_score = 'F'\n",
    "    \n",
    "    if num_score >= 90:\n",
    "        letter_score = 'A'\n",
    "    elif num_score >= 80:\n",
    "        letter_score = 'B'\n",
    "    elif num_score >= 70:\n",
    "        letter_score = 'C'\n",
    "    elif num_score >= 60:\n",
    "        letter_score = 'D'\n",
    "        \n",
    "    return num_score, letter_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
